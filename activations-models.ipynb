{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ibmseti\n",
    "import collections\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import commonutils as cu\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import sklearn\n",
    "import h5py\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models on full dataset - 7 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the activations dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim of data: 114688\n",
      "Number of training images = 11484\n",
      "Number of validation images = 3000\n",
      "Number of test images = 1500\n",
      "Distribution in training images: \n",
      "0 - 1472 \n",
      "1 - 1430 \n",
      "2 - 1431 \n",
      "3 - 2871 \n",
      "4 - 1455\n",
      "Distribution in validation images: \n",
      "0 - 348 \n",
      "1 - 387 \n",
      "2 - 406 \n",
      "3 - 742 \n",
      "4 - 363\n",
      "Distribution in test images: \n",
      "0 - 178 \n",
      "1 - 182 \n",
      "2 - 160 \n",
      "3 - 382 \n",
      "4 - 180\n"
     ]
    }
   ],
   "source": [
    "## Read in all files from directory and combine them into train/val/test datasets\n",
    "dataset = cu.datautils.loadDataset(\"data/activations-4-19.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim of data: 114688\n",
      "Number of training images = 11484\n",
      "Number of validation images = 3000\n",
      "Number of test images = 1500\n",
      "Distribution in training images: \n",
      "0 - 1472 \n",
      "1 - 1430 \n",
      "2 - 1431 \n",
      "3 - 2871 \n",
      "4 - 1455\n",
      "Distribution in validation images: \n",
      "0 - 348 \n",
      "1 - 387 \n",
      "2 - 406 \n",
      "3 - 742 \n",
      "4 - 363\n",
      "Distribution in test images: \n",
      "0 - 178 \n",
      "1 - 182 \n",
      "2 - 160 \n",
      "3 - 382 \n",
      "4 - 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akashmjn/anaconda2/envs/cs341/lib/python2.7/site-packages/keras/utils/np_utils.py:23: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  Y[i, y[i]] = 1.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Loading in and preparing datasets\n",
    "x_train = dataset['x_train']\n",
    "y_train = dataset['y_train']\n",
    "x_val = dataset['x_val']\n",
    "y_val = dataset['y_val']\n",
    "x_test = dataset['x_test']\n",
    "y_test = dataset['y_test']\n",
    "num_val = dataset['x_val'].shape[0]\n",
    "num_test = dataset['x_test'].shape[0]\n",
    "nb_classes = 7\n",
    "\n",
    "# Scaling training and test data\n",
    "means = np.mean(x_train,axis=0)\n",
    "stddev = np.std(x_train,axis=0)\n",
    "# Preventing zero division\n",
    "stddev[stddev<1e-3] = 1\n",
    "x_train = (x_train - means)/stddev\n",
    "x_val = (x_val - means)/stddev\n",
    "x_test = (x_test - means)/stddev\n",
    "\n",
    "# input shape\n",
    "act_shape = x_train[0].shape\n",
    "num_train = x_train.shape[0]\n",
    "\n",
    "# Creating full input vectors \n",
    "X_train = np.reshape(x_train,(num_train,)+act_shape)\n",
    "X_val = np.reshape(x_val,(num_val,)+act_shape)\n",
    "X_test = np.reshape(x_test,(num_test,)+act_shape)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# y_train = np.reshape(y_train,(num_train,))\n",
    "# y_val = np.reshape(y_val,(num_val,))\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_ids',\n",
       " 'x_val',\n",
       " 'x_train',\n",
       " 'y_train',\n",
       " 'val_ids',\n",
       " 'y_val',\n",
       " 'x_test',\n",
       " 'y_test',\n",
       " 'test_ids']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runLinSVMModel(dataset,C,nDataset,modeltype,gamma=None):\n",
    "    x_train = dataset['x_train']\n",
    "    y_train = dataset['y_train']\n",
    "    x_test = dataset['x_test']\n",
    "    y_test = dataset['y_test']\n",
    "    \n",
    "    # Scaling training and test data\n",
    "    means = np.mean(x_train,axis=0)\n",
    "    stddev = np.std(x_train,axis=0)\n",
    "    # Preventing zero division\n",
    "    stddev[stddev<1e-3] = 1\n",
    "    x_train = (x_train - means)/stddev\n",
    "    x_test = (x_test - means)/stddev\n",
    "    \n",
    "    if modeltype=='linSVM':\n",
    "        lin_clf = svm.LinearSVC(C=C/nDataset,verbose=True,class_weight='balanced')\n",
    "        lin_clf.fit(x_train, y_train)\n",
    "        pred_train = lin_clf.predict(x_train)\n",
    "        pred_test = lin_clf.predict(x_test)\n",
    "    elif modeltype=='linSVR':\n",
    "        lin_clf = svm.LinearSVC(C=C/nDataset,verbose=True)\n",
    "        lin_clf.fit(x_train, y_train)\n",
    "        pred_train = np.round(lin_clf.predict(x_train))\n",
    "        pred_test = np.round(lin_clf.predict(x_test))\n",
    "    elif modeltype=='rbfSVM':\n",
    "        lin_clf = svm.SVC(C=C/nDataset,gamma=gamma,verbose=True,class_weight='balanced',\n",
    "                          decision_function_shape='ovr')\n",
    "        lin_clf.fit(x_train, y_train)\n",
    "        pred_train = lin_clf.predict(x_train)\n",
    "        pred_test = lin_clf.predict(x_test)\n",
    "\n",
    "    train_report = sklearn.metrics.classification_report(y_train,pred_train)\n",
    "    test_report = sklearn.metrics.classification_report(y_test,pred_test)\n",
    "\n",
    "    train_confmat = sklearn.metrics.confusion_matrix(y_train,pred_train)\n",
    "    test_confmat = sklearn.metrics.confusion_matrix(y_test,pred_test)\n",
    "    \n",
    "    print train_report\n",
    "    print train_confmat\n",
    "    print test_report\n",
    "    print test_confmat\n",
    "    \n",
    "    print(\"Classification accuracy: %0.2f\" % sklearn.metrics.accuracy_score(y_test,pred_test) )\n",
    "    print(\"MSE: %0.2f\" % np.mean(np.square(y_test - lin_clf.predict(x_test))) )\n",
    "    print(\"Predictions correlation: %0.2f\") % np.corrcoef(y_test,pred_test,rowvar=0)[0,1]\n",
    "    \n",
    "    result = {'train_report':train_report,'train_confmat':train_confmat,\n",
    "             'test_report':test_report,'test_confmat':test_confmat,\n",
    "             'train_score':lin_clf.score(x_train,y_train),\n",
    "             'test_score':lin_clf.score(x_test,y_test) }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.34      0.99      0.50      1472\n",
      "        1.0       0.88      0.58      0.70      1430\n",
      "        2.0       0.70      0.71      0.70      1431\n",
      "        3.0       0.93      0.62      0.75      2871\n",
      "        4.0       0.98      0.60      0.75      1455\n",
      "        5.0       0.86      0.56      0.67      1434\n",
      "        6.0       0.77      0.57      0.65      1391\n",
      "\n",
      "avg / total       0.80      0.66      0.68     11484\n",
      "\n",
      "[[1464    4    0    0    0    1    3]\n",
      " [ 417  830   93   53    7    5   25]\n",
      " [ 328    7 1018   59    1    7   11]\n",
      " [ 710   26  298 1787    2   17   31]\n",
      " [ 372   58   48    8  875   11   83]\n",
      " [ 547    6    1    5    0  796   79]\n",
      " [ 496    8    0    2    8   91  786]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.30      0.98      0.46       178\n",
      "        1.0       0.68      0.45      0.54       182\n",
      "        2.0       0.50      0.61      0.55       160\n",
      "        3.0       0.84      0.55      0.66       382\n",
      "        4.0       0.76      0.46      0.57       180\n",
      "        5.0       0.50      0.36      0.42       193\n",
      "        6.0       0.50      0.24      0.32       225\n",
      "\n",
      "avg / total       0.61      0.51      0.52      1500\n",
      "\n",
      "[[174   0   0   0   0   0   4]\n",
      " [ 56  81  16   7  14   3   5]\n",
      " [ 29   3  97  25   4   1   1]\n",
      " [ 83   8  74 210   2   3   2]\n",
      " [ 49  21   7   2  82   3  16]\n",
      " [ 88   2   0   5   3  69  26]\n",
      " [105   4   0   1   3  59  53]]\n",
      "Classification accuracy: 0.51\n",
      "MSE: 5.95\n",
      "Predictions correlation: 0.39\n"
     ]
    }
   ],
   "source": [
    "a = runLinSVMModel(dataset,1e-2,len(y_train),modeltype='linSVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65795889933820972, 0.51066666666666671)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a['train_score'],a['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 21s    \n",
      "\n",
      "Printing results on val dataset for best saved model: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.38      0.75      0.51       348\n",
      "        1.0       0.53      0.44      0.48       387\n",
      "        2.0       0.55      0.45      0.49       406\n",
      "        3.0       0.62      0.65      0.63       742\n",
      "        4.0       0.67      0.53      0.59       363\n",
      "        5.0       0.53      0.39      0.45       370\n",
      "        6.0       0.46      0.38      0.42       384\n",
      "\n",
      "avg / total       0.55      0.53      0.53      3000\n",
      "\n",
      "[[261  13   2  42   8   8  14]\n",
      " [ 73 171  29  64  33   8   9]\n",
      " [ 59  18 182 126  12   2   7]\n",
      " [ 92  28  99 481   8  11  23]\n",
      " [ 40  51  13  26 194  11  28]\n",
      " [ 88  15   1  23   8 146  89]\n",
      " [ 69  29   4  20  28  87 147]]\n",
      "Test accuracy: 0.53 \n"
     ]
    }
   ],
   "source": [
    "valPred = cu.modelutils.evaluateSavedModel(\\\n",
    "                        \"./savedModels/Class_2048_8x8_resampled_rmsproplr1e-05decay1e-06.hdf5\",dataset,mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 10s    \n",
      "\n",
      "Printing results on test dataset for best saved model: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.39      0.76      0.52       178\n",
      "        1.0       0.49      0.49      0.49       182\n",
      "        2.0       0.47      0.51      0.49       160\n",
      "        3.0       0.66      0.68      0.67       382\n",
      "        4.0       0.66      0.47      0.55       180\n",
      "        5.0       0.49      0.33      0.40       193\n",
      "        6.0       0.45      0.31      0.37       225\n",
      "\n",
      "avg / total       0.54      0.52      0.52      1500\n",
      "\n",
      "[[135   9   4  15   3   3   9]\n",
      " [ 27  89  18  24  13   4   7]\n",
      " [ 14  11  81  44   5   2   3]\n",
      " [ 38  16  57 259   2   3   7]\n",
      " [ 22  35   2  16  85   5  15]\n",
      " [ 52  13   2  14   4  64  44]\n",
      " [ 57   7   7  18  17  49  70]]\n",
      "Test accuracy: 0.52 \n"
     ]
    }
   ],
   "source": [
    "valPred = cu.modelutils.evaluateSavedModel(\\\n",
    "                        \"./savedModels/Class_2048_8x8_resampled_rmsproplr1e-05decay1e-06.hdf5\",dataset,mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'006016'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['val_ids'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Saving misclassifications\n",
    "imgPath = \"./data/specdataimages/\"\n",
    "savePath = \"./data/misclassifications-4-22-c1/\"\n",
    "os.system(\"mkdir -p {}\".format(savePath))\n",
    "for i in range(len(valPred)):\n",
    "    if valPred[i] == 1 and dataset['y_val'][i] != 1:\n",
    "        imgid = dataset['val_ids'][i]\n",
    "        source = \"{}{}.jpg\".format(imgPath,imgid)\n",
    "        dest = \"{}p{}c{}_{}.jpg\".format(savePath,0,int(dataset['y_val'][i]),imgid)\n",
    "        os.system(\"cp {} {}\".format(source,dest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually examining the images above shows that the model has not been trained properly since the false predictions don't seem very consistent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11484, 114688)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a fully connected network of size 2048, this would mean ~ 250M parameters (2048*114688) ~ 900-1800 MB memory depending on 4/8 byte float/double precision. This would be a super wasteful model, but we could quickly try it out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Models on subset of classes - 4 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in a subset of all classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim of data: 114688\n",
      "Number of training images = 7208\n",
      "Number of validation images = 1866\n",
      "Number of test images = 913\n",
      "Distribution in training images: \n",
      "0 - 1472 \n",
      "1 - 1431 \n",
      "2 - 2871 \n",
      "3 - 1434 \n",
      "4 - 0\n",
      "Distribution in validation images: \n",
      "0 - 348 \n",
      "1 - 406 \n",
      "2 - 742 \n",
      "3 - 370 \n",
      "4 - 0\n",
      "Distribution in test images: \n",
      "0 - 178 \n",
      "1 - 160 \n",
      "2 - 382 \n",
      "3 - 193 \n",
      "4 - 0\n"
     ]
    }
   ],
   "source": [
    "# Loading in a dataset with a subset of all classes\n",
    "subsetClasses = {0.0:0.0,2.0:1.0,3.0:2.0,5.0:3.0}\n",
    "dataset = cu.datautils.loadDataset(\"data/activations-4-19.h5\",subsetClasses=subsetClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading in and preparing datasets\n",
    "x_train = dataset['x_train']\n",
    "y_train = dataset['y_train']\n",
    "x_val = dataset['x_val']\n",
    "y_val = dataset['y_val']\n",
    "x_test = dataset['x_test']\n",
    "y_test = dataset['y_test']\n",
    "num_val = dataset['x_val'].shape[0]\n",
    "num_test = dataset['x_test'].shape[0]\n",
    "nb_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.47      1.00      0.64      1472\n",
      "        1.0       0.78      0.74      0.76      1431\n",
      "        2.0       0.99      0.63      0.77      2871\n",
      "        3.0       0.95      0.61      0.74      1434\n",
      "\n",
      "avg / total       0.83      0.72      0.73      7208\n",
      "\n",
      "[[1469    0    0    3]\n",
      " [ 337 1059   23   12]\n",
      " [ 739  302 1799   31]\n",
      " [ 562    1    3  868]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      0.99      0.63       178\n",
      "        1.0       0.55      0.65      0.59       160\n",
      "        2.0       0.89      0.55      0.68       382\n",
      "        3.0       0.92      0.50      0.65       193\n",
      "\n",
      "avg / total       0.75      0.64      0.65       913\n",
      "\n",
      "[[176   0   0   2]\n",
      " [ 31 104  23   2]\n",
      " [ 83  86 209   4]\n",
      " [ 94   0   2  97]]\n",
      "Classification accuracy: 0.64\n",
      "MSE: 1.48\n",
      "Predictions correlation: 0.48\n"
     ]
    }
   ],
   "source": [
    "a = runLinSVMModel(dataset,1e-2,len(y_train),modeltype='linSVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.72072697003329633, 0.6418400876232202)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a['train_score'],a['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cs341]",
   "language": "python",
   "name": "conda-env-cs341-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
