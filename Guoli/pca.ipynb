{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ibmseti\n",
    "import collections\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import commonutils as cu\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import sklearn\n",
    "import h5py\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runLinSVMModel(dataset,C,nDataset,modeltype,printReports=True,gamma=None):\n",
    "    x_train = dataset['x_train']\n",
    "    y_train = dataset['y_train']\n",
    "    x_test = dataset['x_test']\n",
    "    y_test = dataset['y_test']\n",
    "    \n",
    "    # Scaling training and test data\n",
    "    means = np.mean(x_train,axis=0)\n",
    "    stddev = np.std(x_train,axis=0)\n",
    "    # Preventing zero division\n",
    "    stddev[stddev<1e-3] = 1\n",
    "    x_train -= means\n",
    "    x_train /= stddev\n",
    "    x_test -= means\n",
    "    x_test /= stddev\n",
    "    \n",
    "    if modeltype=='linSVM':\n",
    "        lin_clf = svm.LinearSVC(C=C/nDataset,verbose=True,class_weight='balanced')\n",
    "        lin_clf.fit(x_train, y_train)\n",
    "        pred_train = lin_clf.predict(x_train)\n",
    "        pred_test = lin_clf.predict(x_test)\n",
    "    elif modeltype=='linSVR':\n",
    "        lin_clf = svm.LinearSVC(C=C/nDataset,verbose=True)\n",
    "        lin_clf.fit(x_train, y_train)\n",
    "        pred_train = np.round(lin_clf.predict(x_train))\n",
    "        pred_test = np.round(lin_clf.predict(x_test))\n",
    "    elif modeltype=='rbfSVM':\n",
    "        lin_clf = svm.SVC(C=C/nDataset,gamma=gamma,verbose=True,class_weight='balanced',\n",
    "                          decision_function_shape='ovr')\n",
    "        lin_clf.fit(x_train, y_train)\n",
    "        pred_train = lin_clf.predict(x_train)\n",
    "        pred_test = lin_clf.predict(x_test)\n",
    "\n",
    "    train_report = sklearn.metrics.classification_report(y_train,pred_train)\n",
    "    test_report = sklearn.metrics.classification_report(y_test,pred_test)\n",
    "\n",
    "    train_confmat = sklearn.metrics.confusion_matrix(y_train,pred_train)\n",
    "    test_confmat = sklearn.metrics.confusion_matrix(y_test,pred_test)\n",
    "    \n",
    "    if printReports:\n",
    "        print train_report\n",
    "        print train_confmat\n",
    "        print test_report\n",
    "        print test_confmat\n",
    "\n",
    "        print(\"Classification accuracy: %0.2f\" % sklearn.metrics.accuracy_score(y_test,pred_test) )\n",
    "        print(\"MSE: %0.2f\" % np.mean(np.square(y_test - lin_clf.predict(x_test))) )\n",
    "        print(\"Predictions correlation: %0.2f\") % np.corrcoef(y_test,pred_test,rowvar=0)[0,1]\n",
    "    \n",
    "    result = {'train_report':train_report,'train_confmat':train_confmat,\n",
    "             'test_report':test_report,'test_confmat':test_confmat,\n",
    "             'train_score':lin_clf.score(x_train,y_train),\n",
    "             'test_score':lin_clf.score(x_test,y_test) }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_cumulative_variance(pca):\n",
    "    P = []\n",
    "    for p in pca.explained_variance_ratio_:\n",
    "        if len(P) == 0:\n",
    "            P.append(p)\n",
    "        else:\n",
    "            P.append(p + P[-1])\n",
    "    plt.plot(P)\n",
    "    plt.show()\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim of data: 114688\n",
      "Number of training images = 7211\n",
      "Number of validation images = 1832\n",
      "Number of test images = 943\n",
      "Distribution in training images: \n",
      "0 - 1471 \n",
      "1 - 1419 \n",
      "2 - 2888 \n",
      "3 - 1433 \n",
      "4 - 0\n",
      "Distribution in validation images: \n",
      "0 - 343 \n",
      "1 - 376 \n",
      "2 - 723 \n",
      "3 - 390 \n",
      "4 - 0\n",
      "Distribution in test images: \n",
      "0 - 184 \n",
      "1 - 202 \n",
      "2 - 384 \n",
      "3 - 173 \n",
      "4 - 0\n"
     ]
    }
   ],
   "source": [
    "# Loading in a dataset with a subset of all classes\n",
    "subsetClasses = {0.0:0.0,2.0:1.0,3.0:2.0,5.0:3.0}\n",
    "dataset = cu.datautils.loadDataset(\"data/activations-5-1.h5\",subsetClasses=subsetClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading in and preparing datasets\n",
    "x_train = dataset['x_train']\n",
    "y_train = dataset['y_train']\n",
    "x_val = dataset['x_val']\n",
    "y_val = dataset['y_val']\n",
    "x_test = dataset['x_test']\n",
    "y_test = dataset['y_test']\n",
    "num_val = dataset['x_val'].shape[0]\n",
    "num_test = dataset['x_test'].shape[0]\n",
    "nb_classes = 4\n",
    "# Scaling training and test data\n",
    "means = np.mean(x_train,axis=0)\n",
    "stddev = np.std(x_train,axis=0)\n",
    "# Preventing zero division\n",
    "stddev[stddev<1e-3] = 1\n",
    "x_train -= means\n",
    "x_train /= stddev\n",
    "x_val -= means\n",
    "x_val /= stddev\n",
    "x_test -= means\n",
    "x_test /= stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Results for C=0.0125764032241:\n",
      "Train score=0.862432394952   Test score=0.556733828208\n",
      "[LibLinear]Results for C=0.122401203647:\n",
      "Train score=1.0   Test score=0.582184517497\n",
      "[LibLinear]Results for C=0.0806160965178:\n",
      "Train score=1.0   Test score=0.582184517497\n",
      "[LibLinear]Results for C=0.00135991310012:\n",
      "Train score=0.580502010817   Test score=0.498409331919\n",
      "[LibLinear]Results for C=0.0244526945527:\n",
      "Train score=0.958674247677   Test score=0.574761399788\n",
      "[LibLinear]Results for C=0.314272072656:\n",
      "Train score=1.0   Test score=0.574761399788\n",
      "[LibLinear]Results for C=0.00166646363381:\n",
      "Train score=0.596311191236   Test score=0.504772004242\n",
      "[LibLinear]Results for C=0.297857114389:\n",
      "Train score=1.0   Test score=0.577942735949\n",
      "[LibLinear]Results for C=0.530394019778:\n",
      "Train score=1.0   Test score=0.575821845175\n",
      "[LibLinear]Results for C=0.150764541357:\n",
      "Train score=1.0   Test score=0.577942735949\n"
     ]
    }
   ],
   "source": [
    "## Parameter search for SVM\n",
    "C_values = 10**np.random.uniform(-3,0,10)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for C_val in C_values:\n",
    "    a = runLinSVMModel(dataset,C_val,len(dataset['y_train']),printReports=False,modeltype='linSVM')\n",
    "    train_scores.append(a['train_score'])\n",
    "    test_scores.append(a['test_score'])\n",
    "    print \"Results for C={}:\".format(C_val)\n",
    "    print \"Train score={}   Test score={}\".format(a['train_score'],a['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = runLinSVMModel(dataset,1e-1,len(dataset['y_train']),modeltype='linSVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(a['train_score'],a['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim of data: 114688\n",
      "Number of training images = 7208\n",
      "Number of validation images = 1866\n",
      "Number of test images = 913\n",
      "Distribution in training images: \n",
      "0 - 1472 \n",
      "1 - 1431 \n",
      "2 - 2871 \n",
      "3 - 1434 \n",
      "4 - 0\n",
      "Distribution in validation images: \n",
      "0 - 348 \n",
      "1 - 406 \n",
      "2 - 742 \n",
      "3 - 370 \n",
      "4 - 0\n",
      "Distribution in test images: \n",
      "0 - 178 \n",
      "1 - 160 \n",
      "2 - 382 \n",
      "3 - 193 \n",
      "4 - 0\n"
     ]
    }
   ],
   "source": [
    "# 4-19, Loading in a dataset with a subset of all classes\n",
    "subsetClasses = {0.0:0.0,2.0:1.0,3.0:2.0,5.0:3.0}\n",
    "dataset = cu.datautils.loadDataset(\"data/activations-4-19.h5\",subsetClasses=subsetClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading in and preparing datasets\n",
    "x_train = dataset['x_train']\n",
    "y_train = dataset['y_train']\n",
    "x_val = dataset['x_val']\n",
    "y_val = dataset['y_val']\n",
    "x_test = dataset['x_test']\n",
    "y_test = dataset['y_test']\n",
    "num_val = dataset['x_val'].shape[0]\n",
    "num_test = dataset['x_test'].shape[0]\n",
    "nb_classes = 4\n",
    "# Scaling training and test data\n",
    "means = np.mean(x_train,axis=0)\n",
    "stddev = np.std(x_train,axis=0)\n",
    "# Preventing zero division\n",
    "stddev[stddev<1e-3] = 1\n",
    "x_train -= means\n",
    "x_train /= stddev\n",
    "x_val -= means\n",
    "x_val /= stddev\n",
    "x_test -= means\n",
    "x_test /= stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.57      1.00      0.73      1472\n",
      "        1.0       0.96      0.86      0.91      1431\n",
      "        2.0       1.00      0.77      0.87      2871\n",
      "        3.0       0.98      0.78      0.87      1434\n",
      "\n",
      "avg / total       0.90      0.84      0.85      7208\n",
      "\n",
      "[[1472    0    0    0]\n",
      " [ 197 1234    0    0]\n",
      " [ 594   45 2213   19]\n",
      " [ 319    0    0 1115]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.48      0.98      0.64       178\n",
      "        1.0       0.52      0.63      0.57       160\n",
      "        2.0       0.87      0.54      0.67       382\n",
      "        3.0       0.89      0.53      0.66       193\n",
      "\n",
      "avg / total       0.73      0.64      0.64       913\n",
      "\n",
      "[[174   0   0   4]\n",
      " [ 27 101  31   1]\n",
      " [ 77  90 207   8]\n",
      " [ 87   3   1 102]]\n",
      "Classification accuracy: 0.64\n",
      "MSE: 1.42\n",
      "Predictions correlation: 0.48\n"
     ]
    }
   ],
   "source": [
    "a = runLinSVMModel(dataset,1e-1,len(dataset['y_train']),modeltype='linSVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.83712541620421754, 0.63964950711938662)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a['train_score'],a['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-16420a17df3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset_pca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset_pca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_test'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cs341seti/anaconda3/envs/cs341seti/lib/python2.7/site-packages/sklearn/decomposition/pca.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cs341seti/anaconda3/envs/cs341seti/lib/python2.7/site-packages/sklearn/decomposition/pca.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         X = check_array(X, dtype=[np.float64], ensure_2d=True,\n\u001b[0;32m--> 346\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cs341seti/anaconda3/envs/cs341seti/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=1000)\n",
    "pca.fit(dataset['x_train'])\n",
    "dataset_pca = {}\n",
    "dataset_pca['x_train'] = pca.transform(dataset['x_test'])\n",
    "dataset_pca['x_test'] = pca.transform(x_test)\n",
    "dataset_pca['y_test'] = dataset['y_test']\n",
    "dataset_pca['y_train']= dataset['y_train']\n",
    "dataset_pca['x_train'].shape\n",
    "dataset_pca['x_test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = runLinSVMModel(dataset_pca,1e-1,len(dataset['y_train']),modeltype='linSVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Read in all files from directory and combine them into train/val/test datasets\n",
    "# dataset = cu.datautils.loadDataset(\"data/activations-4-19.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f214b9d13585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Preventing zero division\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ## Loading in and preparing datasets\n",
    "# x_train = dataset['x_train']\n",
    "# y_train = dataset['y_train']\n",
    "# x_val = dataset['x_val']\n",
    "# y_val = dataset['y_val']\n",
    "# x_test = dataset['x_test']\n",
    "# y_test = dataset['y_test']\n",
    "# num_val = dataset['x_val'].shape[0]\n",
    "# num_test = dataset['x_test'].shape[0]\n",
    "# nb_classes = 7\n",
    "\n",
    "# # Scaling training and test data\n",
    "# means = np.mean(x_train,axis=0)\n",
    "# stddev = np.std(x_train,axis=0)\n",
    "# # Preventing zero division\n",
    "# stddev[stddev<1e-3] = 1\n",
    "# x_train -= means\n",
    "# x_train /= stddev\n",
    "# x_val -= means\n",
    "# x_val /= stddev\n",
    "# x_test -= means\n",
    "# x_test /= stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading in and preparing datasets\n",
    "x_train = dataset['x_train']\n",
    "y_train = dataset['y_train']\n",
    "x_val = dataset['x_val']\n",
    "y_val = dataset['y_val']\n",
    "x_test = dataset['x_test']\n",
    "y_test = dataset['y_test']\n",
    "num_val = dataset['x_val'].shape[0]\n",
    "num_test = dataset['x_test'].shape[0]\n",
    "nb_classes = 7\n",
    "\n",
    "# Scaling training and test data\n",
    "means = np.mean(x_train,axis=0)\n",
    "stddev = np.std(x_train,axis=0)\n",
    "# Preventing zero division\n",
    "stddev[stddev<1e-3] = 1\n",
    "x_train -= means\n",
    "x_train /= stddev\n",
    "x_val -= means\n",
    "x_val /= stddev\n",
    "x_test -= means\n",
    "x_test /= stddev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
